{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0305f457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "55/55 [==============================] - 3280s 59s/step - loss: 0.8369 - accuracy: 0.6705\n",
      "Epoch 2/3\n",
      "55/55 [==============================] - 2079s 38s/step - loss: 0.4410 - accuracy: 0.8545\n",
      "Epoch 3/3\n",
      "55/55 [==============================] - 2009s 37s/step - loss: 0.2160 - accuracy: 0.9375\n",
      "14/14 [==============================] - 143s 10s/step - loss: 0.2379 - accuracy: 0.9364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23785936832427979, 0.9363636374473572]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############\n",
    "# Vaibhav Lakshmi\n",
    "# Bahar Chidem\n",
    "################\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "\n",
    "file_path = '/Users/bahar/Downloads/first_1100_rows.csv'\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "df['text'] = df['problem'].fillna('') + \" \" + df['solution'].fillna('')  \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['Potential'])\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure all text data is in string format\n",
    "X_train = X_train.astype(str)\n",
    "X_test = X_test.astype(str)\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenization\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(16)\n",
    "\n",
    "# Load BERT model with a classification layer\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Model Compilation\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset.shuffle(100), epochs=3)\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code above is training the model\n",
    "#####################################\n",
    "# The code below is predicting the ideas based on their Potential and provides the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e62e335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 128s 10s/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Modify this for testing w another dataset \n",
    "file_path_new = '/Users/bahar/Downloads/rest_of_the_rows_selected_columns.csv' \n",
    "df_new = pd.read_csv(file_path_new)\n",
    "df_new['text'] = df_new['problem'].fillna('') + \" \" + df_new['solution'].fillna('')\n",
    "\n",
    "new_encodings = tokenizer(df_new['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "new_data = tf.data.Dataset.from_tensor_slices((dict(new_encodings))).batch(16)\n",
    "new_predictions = model.predict(new_data)\n",
    "\n",
    "logits = new_predictions.logits\n",
    "probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "predicted_indices = tf.argmax(probabilities, axis=1)\n",
    "\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_indices)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'text': df_new['text'],\n",
    "    'predicted_potential': predicted_labels\n",
    "})\n",
    "# Modify this for the output\n",
    "output_file_path = '/Users/bahar/Desktop/predictions2.csv'\n",
    "results_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00872081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below provides a feedback based on the predicted label and returns the csv file \n",
    "# with both predicted potential and feedback related to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3a29f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 129s 10s/step\n"
     ]
    }
   ],
   "source": [
    "# Modify this for testing w another dataset \n",
    "file_path_new = '/Users/bahar/Downloads/rest_of_the_rows_selected_columns.csv' \n",
    "df_new['text'] = df_new['problem'].fillna('') + \" \" + df_new['solution'].fillna('')\n",
    "\n",
    "new_encodings = tokenizer(df_new['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "new_data = tf.data.Dataset.from_tensor_slices((dict(new_encodings))).batch(16)\n",
    "new_predictions = model.predict(new_data)\n",
    "\n",
    "# Processing predictions\n",
    "logits = new_predictions.logits\n",
    "probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "predicted_indices = tf.argmax(probabilities, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_indices)\n",
    "\n",
    "# Generate feedback based on predicted labels\n",
    "def generate_feedback(label):\n",
    "    feedback_mapping = {\n",
    "        'High Potential': 'This idea shows high potential with strong resource efficiency, sustainability, and economic viability.',\n",
    "        'Medium Potential': 'This idea has medium potential. Consider improvements in resource efficiency, sustainability, or economic viability.',\n",
    "        'Low Potential': 'This idea has low potential. Assess and enhance resource efficiency, sustainability, and economic viability.',\n",
    "        'Very Low Potential': 'This idea has very low potential. A major rethink or overhaul may be required to improve its viability.'\n",
    "    }\n",
    "    return feedback_mapping.get(label, 'No feedback available')\n",
    "\n",
    "feedback = [generate_feedback(label) for label in predicted_labels]\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'text': df_new['text'],\n",
    "    'predicted_potential': predicted_labels,\n",
    "    'feedback': feedback\n",
    "})\n",
    "# Modify this for the output\n",
    "output_file_path = '/Users/bahar/Desktop/predictions_with_feedback.csv'  \n",
    "results_df.to_csv(output_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
